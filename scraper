#import all the required modules
import re
import csv
from urllib.request import urlopen
from bs4 import BeautifulSoup
import sys
import warnings
from requests_html import HTMLSession
import requests

# #declare a session object
# session = HTMLSession()
#
# #ignore warnings
# if not sys.warnoptions:
#     warnings.simplefilter("ignore")
#
# internal_urls = []
#
# r = requests.get("http://www.kyliecosmetics.com/sitemap_products_1.xml?from=4083591943&to=2373915377743")
# xml = r.text
#
# soup = BeautifulSoup(xml)
# url_xmls = soup.find_all("url")
# for url in url_xmls:
#     internal_urls.append(url.findNext("loc").text)
#
# headers = {
#         'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'
#     }
#
# all_items=[]
#
# for url in internal_urls:
#     item_array=[]
#     response = session.get(url, headers=headers, verify=False)
#
#     price = response.html.find("span", containing='price')
#
#     name = response.html.find('h1', first = True)
#     if name != None:
#         picture = response.html.find('img', containing=name.text)
#
#     if price != None:
#         print(price)
#     else:
#         print('price none')
#     if name != None:
#         print(name.text)
#     else:
#         print('name none')
#     if picture != None:
#         for pic in picture:
#             print(pic.html)
#     else:
#         print('pitcure none')
#
# print(all_items)


r = requests.get("http://www.fentybeauty.com/sitemap_0.xml")
if not sys.warnoptions:
    warnings.simplefilter("ignore")
xml = r.text
internal_urls = []
soup = BeautifulSoup(xml)
url_xmls = soup.find_all("url")
for url in url_xmls:
    internal_urls.append(url.findNext("loc").text)

headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'
    }

all_items=[]
for url in internal_urls:
    item_array=[]
    page = requests.get(url)
    soup = BeautifulSoup(page.content, 'html.parser')

    price = soup.find("span", {"class": re.compile("price")})
    if price == None:
        price = soup.find("p", {"class": re.compile("price")})
    if price == None:
        price = soup.find("div", {"class": re.compile("price")})
    if price != None:
        print(price.text)
    else:
        print('price none')

    name = soup.find("h1", {"class": re.compile("name")})
    if name != None:
        print(name.text)
    else:
        print('name none')